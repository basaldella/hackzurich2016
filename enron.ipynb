{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import multiprocessing\n",
    "import os\n",
    "import datetime\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "line_re = re.compile('^.+ (maildir.+)$')\n",
    "#date_re = re.compile('Date: (Mon|Tue|Wed|Thu|Fri|Sat|Sun), (?P<date>\\d{1,2} [A-Z][a-z]{1,2} \\d{4} \\d\\d:\\d\\d:\\d\\d (\\-|\\+)\\d\\d\\d\\d)')\n",
    "date_re = re.compile('Date: (Mon|Tue|Wed|Thu|Fri|Sat|Sun), (?P<date>\\d{1,2} [A-Z][a-z]{1,2} \\d{4})')\n",
    "enron_fn = '/mnt/storage/hex/projects/clnccr/polcon/enron'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = \"-rw-r--r-- wcohen/users   14236 2004-02-04 01:35 maildir/heard-m/deleted_items/48.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#-rw-r--r-- wcohen/users   14236 2004-02-04 01:35 maildir/heard-m/deleted_items/48.\n",
    "#fns = []\n",
    "fn_date = []\n",
    "with open(enron_fn) as r:  #  + '_small'\n",
    "    for line in r:\n",
    "        if line.strip().endswith('.'):\n",
    "            #print line\n",
    "            email = os.path.join('/mnt/storage/hex/projects/clnccr/polcon/',\n",
    "                                 line_re.match(line).group(1))\n",
    "            with open(email) as r:\n",
    "                count = 0\n",
    "                next(r, None)\n",
    "                date = date_re.search(r.next()).groupdict()['date']\n",
    "                fn_date.append((email, date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 Aug 2000\n"
     ]
    }
   ],
   "source": [
    "with open('/mnt/storage/hex/projects/clnccr/polcon/maildir/campbell-l/north_crawar_remediation/3.') as r:\n",
    "    next(r, None)\n",
    "    date = date_re.search(r.next())\n",
    "    print date.groupdict()['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fn_date_dict = defaultdict(list)\n",
    "for fn, date in fn_date:\n",
    "    fn_split = fn.split('/')[8:]\n",
    "    custodian = fn_split[0]\n",
    "    folder = '/'.join(fn_split[1:-1])\n",
    "    filename = fn_split[-1]\n",
    "    key = custodian, folder, date\n",
    "    fn_date_dict[key].append(filename)\n",
    "fn_date_dict = dict(fn_date_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'31 Aug 2000'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_re.search(d).groupdict()['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def documents_out(custodian, dir_, filenames):\n",
    "    out = []\n",
    "    for filename in filenames:\n",
    "        with open(os.path.join(maildir, custodian, dir_, filename)) as r:\n",
    "            txt = f.read()\n",
    "            out.append((filename, txt))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "body = 'Message-ID: <18322716.1075858011439.JavaMail.evans@thyme>\\r\\nDate: Thu, 17 Feb 2000 09:59:00 -0800 (PST)\\r\\nFrom: greg.whalley@enron.com\\r\\nTo: john.sherriff@enron.com\\r\\nSubject: Re: Announcement of EnronCredit.com\\r\\nCc: bryan.seyfried@enron.com\\r\\nMime-Version: 1.0\\r\\nContent-Type: text/plain; charset=us-ascii\\r\\nContent-Transfer-Encoding: 7bit\\r\\nBcc: bryan.seyfried@enron.com\\r\\nX-From: Greg Whalley\\r\\nX-To: John Sherriff\\r\\nX-cc: Bryan Seyfried\\r\\nX-bcc: \\r\\nX-Folder: \\\\Lawrence_Whalley_Dec2000\\\\Notes Folders\\\\Sent\\r\\nX-Origin: Whalley-L\\r\\nX-FileName: gwhalley.nsf\\r\\n\\r\\nwhat does this new website look like?  can i see a demo version?\\n\\nwhat have we defined as current limits?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id_re = re.compile('^Message-ID: (?P<id>.+)\\r\\n')\n",
    "from_re = re.compile('\\r\\nFrom: (?P<from>.+)\\r\\n')\n",
    "to_re = re.compile('\\r\\nTo: (?P<to>.+)\\r\\n')\n",
    "subj_re = re.compile('\\r\\nSubject: (?P<subject>.+)\\r\\n')\n",
    "cc_re = re.compile('\\r\\nCc: (?P<cc>.+)\\r\\n')\n",
    "bcc_re = re.compile('\\r\\nBcc: (?P<bcc>.+)\\r\\n')\n",
    "body_re = re.compile('X-FileName: .+\\r\\n\\r\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "padding_re = re.compile('^\\d ')\n",
    "date_format = '%d %b %Y %X'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "#import calendar\n",
    "conn = sqlite3.connect('/mnt/storage/hex/projects/clnccr/polcon/www/enron.db')\n",
    "c = conn.cursor()\n",
    "#c.execute('''DROP TABLE emails;''')\n",
    "# Create table\n",
    "c.execute('''CREATE TABLE emails\n",
    "             (id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "              custodian text,\n",
    "              dir text,\n",
    "              date text,\n",
    "              filename text,\n",
    "              message_id text,\n",
    "              from_ text,\n",
    "              to_ text,\n",
    "              subject text,\n",
    "              cc text,\n",
    "              bcc text,\n",
    "              body text)''')\n",
    "\n",
    "maildir = '/mnt/storage/hex/projects/clnccr/polcon/maildir/'\n",
    "# Insert a row of data\n",
    "# Larger example that inserts many records at a time\n",
    "data = []\n",
    "for k, filenames in enron_dict.items():\n",
    "    custodian, dir_, date = k\n",
    "    for filename in filenames:\n",
    "        with open(os.path.join(maildir, custodian, dir_, filename)) as r:\n",
    "            body = r.read().decode('latin1')\n",
    "            id_ = id_re.search(body).groupdict()['id']\n",
    "            from_m = from_re.search(body)\n",
    "            from_ = from_m.groupdict()['from'] if from_m else ''\n",
    "            to_m = to_re.search(body)\n",
    "            to = to_m.groupdict()['to'] if to_m else ''\n",
    "            subj_m = subj_re.search(body)\n",
    "            subj = subj_m.groupdict()['subject'] if subj_m else ''\n",
    "            cc_m = cc_re.search(body)\n",
    "            cc = cc_m.groupdict()['cc'] if cc_m else ''\n",
    "            bcc_m = bcc_re.search(body)\n",
    "            bcc = bcc_m.groupdict()['bcc'] if bcc_m else ''\n",
    "            body = body_re.split(body)[-1]\n",
    "            # padding\n",
    "#             if padding_re.match(date):\n",
    "#                 date = '0' + date\n",
    "#             date_ = datetime.datetime.strptime(date[:-6], date_format)\n",
    "#             # fixing time zones, now all UTC\n",
    "#             hours = datetime.timedelta(hours=int(date[-3]))\n",
    "#             if date[-5] == '-':\n",
    "#                 date_ -= hours\n",
    "#             else:\n",
    "#                 date_ += hours\n",
    "#             # turn to timestap\n",
    "#             date_ = calendar.timegm(date_.timetuple())\n",
    "            data.append((custodian, dir_, date, filename, id_, from_, to, subj, cc, bcc, body))\n",
    "\n",
    "c = conn.cursor()\n",
    "c.executemany('INSERT INTO emails VALUES (?,?,?,?,?,?,?,?,?,?,?,?)', ([i] + list(d) for i, d in enumerate(data)))\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "c.execute('ALTER TABLE emails ADD COLUMN tfidf text;')\n",
    "# had to make another table ...\n",
    "c.execute('CREATE TABLE tfidfs (id integer, words text)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X = [d[-1] + d[-4].encode('utf8') for d in data]\n",
    "tf_idf = TfidfVectorizer(input='content', stop_words='english')\n",
    "X_vect = tf_idf.fit(X)\n",
    "X_vect_ = X_vect.transform(X)\n",
    "\n",
    "feats = X_vect.get_feature_names()\n",
    "num = 5\n",
    "top_tfidfs = []\n",
    "for r in range(X_vect_.shape[0]):\n",
    "    if r % 2500 == 0:\n",
    "        # add top-num tfidf scoring tokens\n",
    "        #c.executemany('UPDATE emails SET tfidf=? WHERE id=?', top_tfidfs)\n",
    "        c.executemany('INSERT INTO tfidfs (words, id) VALUES (?, ?)', top_tfidfs)\n",
    "        top_tfidfs = []\n",
    "    tmp = X_vect_[r].toarray().ravel()\n",
    "    num_ = tmp.nonzero()[0].size\n",
    "    num_ = num if num_ > num else num_\n",
    "    top = np.argpartition(-tmp.ravel(), num_)[:num_]\n",
    "    top_tfidfs.append((' '.join([feats[t] for t in top]), r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "X = []\n",
    "y = []\n",
    "enron_span = '/home/user/makarov/hexmnt/polcon/enron_spam'\n",
    "for i in range(1,7,1):\n",
    "    dir_ = os.path.join(enron_span, 'enron' + str(i))\n",
    "    for label, num_label in [('spam', 1), ('ham', 0)]:\n",
    "        tmp = [open(fn).read().decode('latin1') for fn in glob.glob(os.path.join(dir_, label) + '/*txt')]\n",
    "        X += tmp\n",
    "        y += [num_label] * len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "vect = CountVectorizer(input='content', stop_words='english')\n",
    "\n",
    "X_train_vect = vect.fit_transform(X_train)\n",
    "sgd = SGDClassifier(loss='log', verbose=True)\n",
    "sgd.fit(X_train_vect, y_train)\n",
    "\n",
    "X_test_vect = vect.transform(X_test)\n",
    "pred = sgd.predict(X_test_vect)\n",
    "print f1_score(pred, y_test)\n",
    "# out-of-sample f1-score 0.984665290475\n",
    "\n",
    "# retrain on all data\n",
    "pipeline = make_pipeline(CountVectorizer(input='content', stop_words='english'),\n",
    "                         SGDClassifier(loss='log', verbose=True))\n",
    "pipeline.fit_transform(X, y)\n",
    "\n",
    "joblib.dump(pipeline, os.path.join(enron_span, 'sgd.pkl'))\n",
    "pipeline = joblib.load(os.path.join(enron_span, 'sgd.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/mnt/storage/hex/users/makarov'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.execute('ALTER TABLE tfidfs ADD COLUMN spam boolean;')\n",
    "c.executemany('UPDATE tfidfs SET spam=? WHERE id=?', enumerate(predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
